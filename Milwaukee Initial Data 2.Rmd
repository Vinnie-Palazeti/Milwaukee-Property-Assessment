---
title: "Milwaukee Initial Data"
author: "Brandon Ristoff"
date: "9/24/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



Library
#install.packages("StepAIC")
```{r}
library(tidyverse)
library(ggplot2)
library(sf)
library(lme4)
library(lmerTest)
library(MuMIn)
library(corrplot)
library(Kendall)
library(lubridate)
library(MASS)
library(Hmisc)
library(glmnet)
library(car)
#library(EnvStats)
library(gglasso)
library(MatchIt)

summarize <- dplyr::summarize
select <- dplyr::select
year <- lubridate::year
month <- lubridate::month
```

Assignment Configuration
```{r}
#setwd("C:/Users/bcris/OneDrive/Desktop")
#setwd("C:/Users/Vinnie/Documents")


# Assign Census Data
#popdat <- read.csv("C:/Users/Vinnie/Desktop/GitHub/Milwaukee-Property-Assessment/Census Data.csv") %>% select(-c("X"))
#povdat <- read.csv("C:/Users/Vinnie/Desktop/GitHub/Milwaukee-Property-Assessment/Census Poverty Data.csv") %>% select(-c("X","STATE","COUNTY","NAME","MEDIAN.INCOME"))

# MAC
popdat <- read.csv("/Users/vinniepalazeti/Desktop/GitGit/Milwaukee-Property-Assessment/Census Data.csv")

povdat <- read.csv("/Users/vinniepalazeti/Desktop/GitGit/Milwaukee-Property-Assessment/Census Poverty Data.csv") %>% select(-c("X","STATE","COUNTY","NAME","MEDIAN.INCOME"))


# Assign Assessment Data
setwd("/Users/vinniepalazeti/Desktop/Consulting/Data")
load("res_data_w_geo.dta")

resdata <- data.frame(res_data_w_geo)

#https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3438838

```



# Propensity score matching
# Take observations in majority black neighborhoods & do propensity score matching
# find homes not in majority black neighborhoods & match them


# with this matched data see if there are differences in the ats ratio


# try to do some new models with some more interpretable predictors

# build up to the random effect model with differences in land size & sale price & shit

# simpler models, see what comes of it


# spatial anlaysis
# what other kinds of spatial analysis are there?

# The lasso

# even though no longer holding things constant, that which we have tossed is colinear with what is currently in the model

# YOU SHOULDNT USE SALE PRICE IT IS PART OF THE ASSESSMENT RATIO

# why not use the ASSESSMENT VALUE as the dependent ratio & just control for the sale price

####### TO DO ##########


Build Tract Only Models

Set up New Models with structure
# just use sale price as a covariate to control for & infer on the rest of the variables

Use Lasso to determine best model & infer coefficients

Do propensity score matching on Majority black observations, then use logistic regression on those observations with 1 stdeviation below the mean value

Format & Interpret everything Monday Morning

Cleaning
```{r}
# Left Join Census Data
resdata <- resdata %>% left_join(popdat, by = "GEO_TRACT") %>% left_join(povdat, by= "GEO_TRACT")
resdata <- resdata %>% replace(is.na(.),0)


`%notin%` <- Negate(`%in%`)

#summary(resdata$SALEDATE) #Two Years of Data
#summary(resdata$SALEPRICE) #Nothing Above $10M
#summary(resdata$ASSESSEDVAL)

#1 : Only Ordinary Sales

#2. Eliminate Implausible Values (<$20k, $10M) and no NA values
resdata <- filter(resdata, SALEPRICE >= 20000)
resdata <- filter(resdata, SALEPRICE <= 10000000)
resdata <- filter(resdata, NUM_BLDS == 1) #Check on this

#https://city.milwaukee.gov/ImageLibrary/Groups/ccClerk/Ordinances/Volume-2/CH295-sub5.pdf
resdata <- filter(resdata, grepl('R', ZONING))

# Colin recommended removing Type 11,13,14, & 22
resdata <- filter(resdata, BLDTYPE != "11 - Duplex O/S" & 
                    BLDTYPE != "13 - Duplex-Cottage" & 
                    BLDTYPE != "14 - Multiple Residential Bldgs" & 
                    BLDTYPE != "22 - Dplx Bungalow")

# The first seven categories comprise 93% of the observations
resdata %>% 
  group_by(BLDTYPE) %>% 
  summarise(n = n()) %>%
  arrange(desc(n)) %>%
  slice(1:7) %>%
  summarise(total = sum(n)/nrow(resdata))

blds <- resdata %>% 
  group_by(BLDTYPE) %>% 
  summarise(n = n()) %>%
  arrange(desc(n)) %>%
  slice(1:7) %>% select(BLDTYPE)

resdata <- resdata %>%
  mutate(BLDTYPE_recode = case_when(
    BLDTYPE %in% blds$BLDTYPE ~ BLDTYPE,
    BLDTYPE %notin% blds$BLDTYPE ~ "Other",
    TRUE ~ as.character(BLDTYPE)
  ))

# Dummy variables for BLDType
resdata$Ranch <- ifelse(resdata$BLDTYPE_recode == "01 - Ranch",1,0)
resdata$Cape_Cod <- ifelse(resdata$BLDTYPE_recode == "04 - Cape Cod",1,0)
resdata$Milwaukee_Bungalow <- ifelse(resdata$BLDTYPE_recode == "18 - Milwaukee Bungalow",1,0)
resdata$Res_OS_A <- ifelse(resdata$BLDTYPE_recode == "19 - Res O/S A & 1/2",1,0)
resdata$Colonial <- ifelse(resdata$BLDTYPE_recode == "05 - Colonial",1,0)
resdata$Duplex <- ifelse(resdata$BLDTYPE_recode == "12 - Duplex N/S",1,0)
resdata$Res_OS_2sty <- ifelse(resdata$BLDTYPE_recode == "08 - Res O/S 2sty +",1,0)
resdata$Other <- ifelse(resdata$BLDTYPE_recode == "Other",1,0)

# Dummy variables for Kitchen Rating
#table(resdata$KITCHEN_RTG)
resdata$Kitchen_Average <- ifelse(resdata$KITCHEN_RTG == "AV - Average",1,0)
resdata$Kitchen_Excellent <- ifelse(resdata$KITCHEN_RTG == "EX - Excellent",1,0)
resdata$Kitchen_Fair <- ifelse(resdata$KITCHEN_RTG == "FR - Fair",1,0)
resdata$Kitchen_Good <- ifelse(resdata$KITCHEN_RTG == "GD - Good",1,0)
resdata$Kitchen_Poor <- ifelse(resdata$KITCHEN_RTG == "PR - Poor",1,0)
resdata$Kitchen_VeryGood <- ifelse(resdata$KITCHEN_RTG == "VG - Very Good",1,0)
resdata$Kitchen_VeryPoor <- ifelse(resdata$KITCHEN_RTG == "VP - Very Poor",1,0)

# Dummy variables for Full Bath Rating
#table(resdata$FULLBATH_RTG)
resdata$FullBath_Average <- ifelse(resdata$FULLBATH_RTG == "AV - Average",1,0)
resdata$FullBath_Excellent <- ifelse(resdata$FULLBATH_RTG == "EX - Excellent",1,0)
resdata$FullBath_Fair <- ifelse(resdata$FULLBATH_RTG == "FR - Fair",1,0)
resdata$FullBath_Good <- ifelse(resdata$FULLBATH_RTG == "GD - Good",1,0)
resdata$FullBath_Poor <- ifelse(resdata$FULLBATH_RTG == "PR - Poor",1,0)
resdata$FullBath_VeryGood <- ifelse(resdata$FULLBATH_RTG == "VG - Very Good",1,0)

# Reformat Date
resdata$SALEDATE <- resdata$SALEDATE %>% ymd()
resdata$SaleYear <- year(resdata$SALEDATE)
resdata$SaleMonth <- month(resdata$SALEDATE)

# Values not present in data
#unique(resdata$TYPE)

# Majority are NA
#resdata %>% 
#  filter(is.na(TYPE))

# Remove one observation missing Assessment Value
resdata <- filter(resdata, !is.na(resdata$ASSESSEDVAL))

#3. Single Family Homes Only

#4. Eliminate Implausible Assessed-to-Sale Ratios (outside the 1.5xIQR range)
resdata$atsratio <- resdata$ASSESSEDVAL/resdata$SALEPRICE

#quantile(resdata$atsratio)

#5. Adjust for inflation in 2019

#Lower End
le <- as.numeric(quantile(resdata$atsratio)[2]) - 1.5*IQR(resdata$atsratio)
#Upper End
ue <- as.numeric(quantile(resdata$atsratio)[4]) + 1.5*IQR(resdata$atsratio)

resdata <- filter(resdata, atsratio >= le)
resdata <- filter(resdata, atsratio <= ue)

#summary(resdata$atsratio)

#5. How to Account for Sales Chasing
# Don't Need To


# recode Building Type

resdata <- resdata %>% 
  mutate(BLDTYPE = ifelse(BLDTYPE == "C018 - Milwaukee Bungalow",
                          "18 - Milwaukee Bungalow",
                          BLDTYPE))
# recode quality
resdata <- resdata %>% mutate(QUAL = ifelse(QUAL == "AA- - AA-","A- - A-", QUAL))

resdata <- resdata %>%
  mutate(QUAL_recode = case_when(
    QUAL %in% c("A+ - A+","A - A","A- - A-") ~ "A",
    QUAL %in% c("B+ - B+","B - B","B- - B-") ~ "B",
    QUAL %in% c("C+ - C+","C - C","C- - C-") ~ "C",
    QUAL %in% c("D+ - D+","D - D","D- - D-") ~ "D",
    QUAL %in% c("E+ - E+") ~ "E",
    QUAL == "M&S 2 - Average" ~ "NA",
    TRUE ~ as.character(QUAL)
    
  ))

# Quality Dummies
#table(resdata$QUAL_recode)
resdata$Qual_A <- ifelse(resdata$QUAL_recode == "A",1,0)
resdata$Qual_B <- ifelse(resdata$QUAL_recode == "B",1,0)
resdata$Qual_C <- ifelse(resdata$QUAL_recode == "C",1,0)
resdata$Qual_D <- ifelse(resdata$QUAL_recode == "D",1,0)
resdata$Qual_E <- ifelse(resdata$QUAL_recode == "E",1,0)
resdata$Qual_NA <- ifelse(resdata$QUAL_recode == "NA",1,0)

# Condition Dummies
#table(resdata$COND)
resdata$Cond_Average <- ifelse(resdata$COND == "AV - Average",1,0)
resdata$Cond_Excellent <- ifelse(resdata$COND == "EX - Excellent",1,0)
resdata$Cond_Fair <- ifelse(resdata$COND == "FR - Fair",1,0)
resdata$Cond_Good <- ifelse(resdata$COND == "GD - Good",1,0)
resdata$Cond_Poor <- ifelse(resdata$COND == "PR - Poor",1,0)
resdata$Cond_VeryGood <- ifelse(resdata$COND == "VG - Very Good",1,0)
resdata$Cond_VeryPoor <- ifelse(resdata$COND == "VP - Very Poor",1,0)


# log Land Size
resdata$LogLandSize <- log(resdata$LANDSIZE)


######### NEW FILTER #############

# Only keeping same unit in Land Size
resdata <- resdata %>% filter(LANDSIZEUNITS == "FF - Front Feet")

# Taking the latest sale date
resdata <- resdata %>% group_by(PID) %>%
  filter(SALEDATE == max(SALEDATE))

# there are 3 duplicate cases
resdata %>% group_by(PID) %>% summarise(n = n()) %>% filter(n > 1)

# removes 3 duplicates
resdata <- resdata %>% distinct(PID, .keep_all = TRUE)

```

## Census Demographics
```{r}

# Median Neighborhood Price
info <- resdata %>%
  group_by(GEO_TRACT) %>%
  summarise(MedianTractSalesPrice = median(SALEPRICE),
            LogMedianTractSalesPrice = log(MedianTractSalesPrice),
            MedianLandSize = median(LANDSIZE),
            LogMedianLandSize = log(MedianLandSize),
            MedianTractATSRatio = median(atsratio))

resdata <- resdata %>% left_join(info, by="GEO_TRACT")

resdata$Meanatsratio <- mean(resdata$atsratio)
resdata$Medianatsratio <- median(resdata$atsratio)
resdata$StandardDev_atsratio <- sd(resdata$atsratio)


resdata <- resdata %>% 
  mutate(
    
    
    
        # Log Sales Price
        LogSalesPrice = log(SALEPRICE),
        
        ATSDeviation = (atsratio - Meanatsratio),

        ATSDev_Indicator = ifelse(abs(ATSDeviation) > StandardDev_atsratio, 1,0 ),
        
        ATSDev_Indicator_LOW = ifelse((ATSDeviation < 0) & (abs(ATSDeviation) > StandardDev_atsratio), 1,0 ),
        
        # Log Median Income
        LogMedianIncome = log(MEDIAN.INCOME),
        
        # Log Assessed Val
        LogAssessedVal = log(ASSESSEDVAL),
        
        # Deviation from Sales Price
        PriceDeviation = (SALEPRICE - MedianTractSalesPrice),
        PctSalePriceDiff = ((SALEPRICE-MedianTractSalesPrice)/MedianTractSalesPrice)*100,
        PctSalePriceDiff_Above = ifelse(PctSalePriceDiff > 0, PctSalePriceDiff,0),
        PctSalePriceDiff_Below = ifelse(PctSalePriceDiff < 0, PctSalePriceDiff,0),
        
        # Deviation From Land Size
        LandSizeDeviation = (LANDSIZE - MedianLandSize),
        PctLandSizeDiff = ((LANDSIZE-MedianLandSize)/MedianLandSize)*100,
        PctLandSizeDiff_Above = ifelse(PctLandSizeDiff > 0, PctLandSizeDiff,0),
        PctLandSizeDiff_Below = ifelse(PctLandSizeDiff < 0, PctLandSizeDiff,0),
        
        
        # Racial Demographics
        Percent_Black = BLACK.POP/TOTAL.POP,
        Majority_Black = ifelse(Percent_Black > 0.5,1,0),
        Percent_White = WHITE.POP/TOTAL.POP,
        Percent_NotHispanic_White = NOT.HISPANIC.WHITE/TOTAL.POP,
        Majority_White = ifelse(Percent_NotHispanic_White > 0.5,1,0),
        Percent_Hispanic = TOTAL.HISPANIC.POP/TOTAL.POP,
        Majority_Hispanic = ifelse(Percent_Hispanic > 0.5,1,0),
        
        # Socio-Economic
        Percent_Renter = RENTER.OCCUPIED.HOUSING.UNITS/TOTAL.POP.IN.HOUSING.UNITS,
        Majority_Renter = ifelse(Percent_Renter > 0.5,1,0),
        POPBelowPovIncomeRatio = sum(POP.BELOW..50.INCOME.POV.RATIO,POP..50..99.INCOME.POV.RATIO,POP.1.00.1.24.INCOME.POV.RATIO),
        Percent_POPBelowPovIncomeRatio = POPBelowPovIncomeRatio/TOTAL.POP,
        Percent_TotalPOPIncomeBelowPovRate = TOTAL.POP.INCOME.BELOW.POV.RATE/TOTAL.POP,
        Percent_BlackIncomeBelowPovRate = BLACK.POP.INCOME.BELOW.POV.RATE/TOTAL.POP,
        Percent_WhiteIncomeBelowPovRate = WHITE.POP.INCOME.BELOW.POV.RATE/TOTAL.POP
        )


```



#### Summaries

## Variables
```{r}
# Sale Price
resdata$salesdecile <- ntile(resdata$SALEPRICE, 10) 
resdata$salesquintile <- ntile(resdata$SALEPRICE, 5)

# Median Neighborhood Price
resdata$MedSalesDecile <- ntile(resdata$MedianTractSalesPrice,10)

# ATS Ratio
resdata$atsratiodecile <- ntile(resdata$atsratio,10)


# Percent Black 
resdata$blackquintile <- ntile(resdata$Percent_Black,5)
resdata$blackdecile <- ntile(resdata$Percent_Black,10)

# Percent White 
resdata$whitequintile <- ntile(resdata$Percent_White,5)
resdata$whitedecile <- ntile(resdata$Percent_White,10)

resdata$white_nonhispanic_decile <- ntile(resdata$Percent_NotHispanic_White,10)

# Percent Hispanic
resdata$hispaniddecile <- ntile(resdata$Percent_Hispanic,10)


# Percent Renter 
resdata$renterquintile <- ntile(resdata$Percent_Renter,5)
resdata$renterdecile <- ntile(resdata$Percent_Renter,10)

# Income 
resdata$IncomeDecile <- ntile(resdata$MEDIAN.INCOME,10)

# Black Income Poverty Rate
resdata$BlackIncome_PovertyRateDecile <- ntile(resdata$Percent_BlackIncomeBelowPovRate,10)

# White Income Poverty Rate
resdata$WhiteIncome_PovertyRateDecile <- ntile(resdata$Percent_WhiteIncomeBelowPovRate,10)


# Total Population Income Below Poverty Rate
resdata$TotalPOPIncome_PovertyRateDecile <- ntile(resdata$Percent_TotalPOPIncomeBelowPovRate,10)

# Total Population Below Poverty Income Ratio
resdata$POPIncome_PovertyRatioDecile <- ntile(resdata$POPBelowPovIncomeRatio,10)
```

Clean
```{r}
resdata$KITCHEN_FAC <- factor(resdata$KITCHEN_RTG)
resdata$COND_FAC <- factor(resdata$COND)
resdata$QUAL_FAC <- factor(resdata$QUAL_recode)
resdata$BATH_FAC <- factor(resdata$FULLBATH_RTG)
resdata$TYPE_FAC <- factor(resdata$BLDTYPE_recode)
resdata$PRIM_WALL <- factor(resdata$PRIM_WALL)
resdata$salemonth <- format(as.Date(resdata$SALEDATE), "%m")
resdata$saleyear <- format(as.Date(resdata$SALEDATE), "%Y")
resdata$age <- 2019 - as.numeric(resdata$YEARBLT)

resdata <- resdata %>% ungroup()

```




## Tables
```{r}
# Median Neighborhood Price
tapply(resdata$atsratio, resdata$MedSalesDecile, summary)


# Assess Ratio by Sales Decile & Quintile
tapply(resdata$atsratio, resdata$salesdecile, summary)
tapply(resdata$atsratio, resdata$salesquintile, summary)

# Sales Prices in Deciles
tapply(resdata$SALEPRICE, resdata$salesdecile, summary)


# Assess Ratio by Percent Black Quintile
tapply(resdata$atsratio,resdata$blackquintile, summary)
tapply(resdata$atsratio,resdata$blackdecile, summary)

# Assess Ratio by Percent White Quintile
tapply(resdata$atsratio,resdata$whitequintile, summary)
tapply(resdata$atsratio,resdata$whitedecile, summary)

# Assess Ratio by Percent Hispanic Decile
tapply(resdata$atsratio, resdata$hispaniddecile,summary)

# Assess Ratio by Percent Renter Quintile
tapply(resdata$atsratio,resdata$renterquintile, summary)
tapply(resdata$atsratio,resdata$renterdecile, summary)

# Income Deciles
tapply(resdata$atsratio,resdata$IncomeDecile, summary)

# Black Income Poverty Rate
tapply(resdata$atsratio,resdata$BlackIncome_PovertyRateDecile, summary)

# White Income Poverty Rate
tapply(resdata$atsratio,resdata$WhiteIncome_PovertyRateDecile, summary)

# Total Population Income Below Poverty Rate
tapply(resdata$atsratio,resdata$TotalPOPIncome_PovertyRateDecile, summary)


# Total Population Below Poverty Income Ratio
tapply(resdata$atsratio,resdata$POPIncome_PovertyRatioDecile, summary)
tapply(resdata$atsratio, resdata$MedSalesDecile, summary)

```


EXTRA WORK


```{r}

# only a 2% difference in Black & White Neighborhoods
(mean(Maj_White$atsratio)-mean(Maj_Black$atsratio))/mean(Maj_White$atsratio)*100


# Geo Tract
summary(as.factor(resdata$GEO_TRACT))
tapply(resdata$atsratio, resdata$GEO_TRACT, mean)


summary(resdata$MedianTractSalesPrice)
summary(resdata$PctSalePriceDiff)

1000 + (1000*sqrt(var(resdata$atsratio)) * 0.12)

#resdata %>% filter(IncomeDecile == 10 & salesdecile == 10) %>% select(SALEPRICE,ASSESSEDVAL)

subblack <- resdata %>% filter(blackdecile > 7)

subwhite <- resdata %>% filter(white_nonhispanic_decile > 7)

ggplot(subblack, aes(BEDROOMS)) + 
  geom_bar()+ 
  ylim(0,1000)

ggplot(subwhite, aes(BEDROOMS)) + 
  geom_bar() + 
  ylim(0,1000)


ggplot(subblack, aes(atsratio)) +
  geom_histogram(bins = 200) +
  xlab("ATS Ratio") + 
  ylab("Frequency")+ 
  xlim(0.5,1.4) + 
  ylim(0,50)


ggplot(subwhite, aes(atsratio)) +
  geom_histogram(bins = 200) +
  xlab("ATS Ratio") + 
  ylab("Frequency") + 
  xlim(0.5,1.4) + 
  ylim(0,50)


# do line plots

median(subblack$atsratio)
mean(subblack$atsratio)

median(subwhite$atsratio)
mean(subwhite$atsratio)


boxplot(subwhite$atsratio,subblack$atsratio)

t.test(subwhite$atsratio,subblack$atsratio)

```



Correlations
```{r}

Observation_independents <- resdata %>% 
  select(atsratio,SALEPRICE,YEARBLT,LANDSIZE, SaleYear,SaleMonth,ASSESSEDVAL, Kitchen_Average, Kitchen_Excellent, Kitchen_Fair, Kitchen_Good, Kitchen_Poor, Kitchen_VeryGood, Kitchen_VeryPoor, KITCHENS, FullBath_Average,FullBath_Excellent,FullBath_Fair,FullBath_Good,FullBath_Poor,FullBath_VeryGood,FULLBATHS, Cond_VeryPoor,Cond_Average,Cond_Excellent,Cond_Fair,Cond_Good,Cond_Poor,Cond_VeryGood, Qual_A,Qual_B,Qual_C,Qual_C,Qual_D,Qual_E, BEDROOMS, Ranch,Cape_Cod,Milwaukee_Bungalow,Res_OS_A,Colonial,Duplex,Res_OS_2sty,Other)

Obs_cors <- cor(Observation_independents)

corrplot(Obs_cors,method='circle', type = 'lower', tl.col="black")


Tract_independents <- resdata  %>% select(GEO_TRACT,MedianATSRatio,MEDIAN.INCOME,Percent_Black,Percent_NotHispanic_White,Percent_Hispanic,Percent_TotalPOPIncomeBelowPovRate)

Tract_independents <- Tract_independents %>% 
  select(-c(GEO_TRACT))

Tract_cors <- cor(Tract_independents)

corrplot(Tract_cors,method='circle', type = 'lower', tl.col="black")

```







# Tract Level

MedianATSRatio
Percent_NotHispanic_White
Percent_Black
Percent_Hispanic

Percent_TotalPOPIncomeBelowPovRate
MEDIAN.INCOME

# Observation Level

SALEPRICE
BLDTYPE
YEARBLT
LANDSIZE
LANDVAL
IMPROVEDVAL
ASSESSEDVAL
SALEDATE
NUM_BLDS
QUAL
COND
BEDROOMS

PRIM_WALL
KITCHEN
KITCHEN_RTG
FULLBATHS
FULLBATH_RTG



```{r}
table(resdata$KITCHEN_RTG)

table(resdata$PRIM_WALL)


```




EDA Trends

```{r}

anova(lm(MedianATSRatio ~ GEO_TRACT,data=resdata)) ; lm(MedianATSRatio ~ GEO_TRACT,data=resdata) 

anova(lm(atsratio ~ GEO_TRACT,data=resdata)) ; lm(atsratio ~ GEO_TRACT,data=resdata) 

```

# Question for matthews

# we are model building & concerned about multicolinarity
# in inferential statistics, how big of an issue is this?
# does not interpreting the correlated variables change anything?
# 

# we see that, say Median income & percent black population are highly correlated
# but also, both of these variables are of peak interest
# how do we go about including them in the model for inferential purposes? or what 
# is generally the best practice?


# Not only is corr a problem, but VIF is an issue
# Check VIF, see if it is huge
# VIF from lm, function called VIF


Fits
```{r}
fitdata <- resdata %>% 
  select(atsratio,Percent_Black,Percent_Renter,Percent_POPBelowPovIncomeRatio,PctSalePriceDiff_Above,PctSalePriceDiff_Below,LogMedianIncome,LogMedianTractSalesPrice,GEO_TRACT)

scaled.dat <- fitdata %>% 
  select(-c("GEO_TRACT")) %>% scale(center = T,scale=T)

fitdata <- as.data.frame(scaled.dat) %>% 
  mutate(GEO_TRACT = fitdata$GEO_TRACT)



# for some reason Price Deviation blows up the model
mod1 <- lmer(atsratio ~ LogMedianIncome + Percent_Black + Percent_Renter + Percent_POPBelowPovIncomeRatio + LogMedianTractSalesPrice  + PctSalePriceDiff_Above + PctSalePriceDiff_Below + (1|GEO_TRACT), data = fitdata)

# RF source of variability
# if GEOtract as fixed effect, losing df
# only loosing 1 df with RF, 

summary(mod1)
anova(mod1)

ICC = (0.07752)/(0.75515+0.07752)
ICC

r.squaredGLMM(mod1)

# Of the variance of an observation, 9.3% of this variation is the result of differences 
# between Census Tracts. 

# 90.7% of this variation is the result of differences within Census Tracts


fitdata1.5 <- resdata %>% 
  select(atsratio,Percent_White,Percent_Renter,Percent_POPBelowPovIncomeRatio,PctSalePriceDiff_Above,PctSalePriceDiff_Below,LogMedianIncome,LogMedianTractSalesPrice,GEO_TRACT)

scaled.dat <- fitdata1.5 %>% 
  select(-c("GEO_TRACT")) %>% scale(center = T,scale=T)

fitdata1.5 <- as.data.frame(scaled.dat) %>% 
  mutate(GEO_TRACT = fitdata1.5$GEO_TRACT)

mod1.5 <- lmer(atsratio ~ LogMedianIncome + Percent_White + Percent_Renter + Percent_POPBelowPovIncomeRatio + LogMedianTractSalesPrice  + PctSalePriceDiff_Above + PctSalePriceDiff_Below + (1|GEO_TRACT), data = fitdata1.5)

summary(mod1.5)
anova(mod1.5)

r.squaredGLMM(mod1.5)

#######################


fitdata1.5 <- resdata %>% 
  select(atsratio,Percent_White,Percent_Renter,Percent_POPBelowPovIncomeRatio,PctSalePriceDiff_Above,PctSalePriceDiff_Below,LogMedianIncome,LogMedianTractSalesPrice,GEO_TRACT)

scaled.dat <- fitdata1.5 %>% 
  select(-c("GEO_TRACT")) %>% scale(center = T,scale=T)

fitdata1.5 <- as.data.frame(scaled.dat) %>% 
  mutate(GEO_TRACT = fitdata1.5$GEO_TRACT)

mod1.5 <- lmer(atsratio ~ LogMedianIncome + Percent_White + Percent_Renter + Percent_POPBelowPovIncomeRatio + LogMedianTractSalesPrice  + PctSalePriceDiff_Above + PctSalePriceDiff_Below + (1|GEO_TRACT), data = fitdata1.5)

summary(mod1.5)
anova(mod1.5)

r.squaredGLMM(mod1.5)

#######################

r.squaredGLMM(mod2)fitdata2 <- resdata %>% 
  select(atsratio,Percent_Black,Percent_White,whitedecile,blackdecile,LogMedianIncome,PctSalePriceDiff_Above,PctSalePriceDiff_Below,GEO_TRACT)


mod2 <- lmer(atsratio ~ blackdecile + (1|GEO_TRACT), data = fitdata2)

summary(mod2)
anova(mod2)


#######################


mod3 <- lmer(atsratio ~  whitedecile + (1|GEO_TRACT), data = fitdata2)

summary(mod3)
anova(mod3)

r.squaredGLMM(mod3)

#######################

mod4 <- lmer(atsratio ~ Percent_Black + (1|GEO_TRACT), data = fitdata2)

summary(mod4)
anova(mod4)

r.squaredGLMM(mod4)

#######################


mod5 <- lmer(atsratio ~  Percent_White + (1|GEO_TRACT), data = fitdata2)

summary(mod5)
anova(mod5)

r.squaredGLMM(mod5)
```

Regression attempts
```{r}
fitdata <- resdata %>% 
  select(atsratio,
         Percent_Black,
         PctSalePriceDiff_Below,PctSalePriceDiff_Above,PctSalePriceDiff_Below,
         LogMedianIncome,LogMedianTractSalesPrice,GEO_TRACT)
 
scaled.dat <- fitdata %>% 
  select(-c("GEO_TRACT")) %>% scale(center = T,scale=T)

fitdata <- as.data.frame(scaled.dat) %>% 
  mutate(GEO_TRACT = fitdata$GEO_TRACT)

covariates <- resdata %>% select(Kitchen_Excellent, Kitchen_Fair, Kitchen_Good, Kitchen_Poor, Kitchen_VeryGood, Kitchen_VeryPoor, KITCHENS,FullBath_Excellent,FullBath_Fair,FullBath_Good,FullBath_Poor,FullBath_VeryGood,FULLBATHS, Cond_VeryPoor,Cond_Excellent,Cond_Fair,Cond_Good,Cond_Poor,Cond_VeryGood, Qual_A,Qual_B,Qual_D,Qual_E, BEDROOMS,Cape_Cod,Milwaukee_Bungalow,Res_OS_A,Colonial,Duplex,Res_OS_2sty,Other)

fitdata <- cbind(fitdata,covariates)

mod <- lmer(atsratio ~ LogMedianIncome + Percent_Black + LogMedianTractSalesPrice  + PctSalePriceDiff_Above + PctSalePriceDiff_Below + (1|GEO_TRACT) + Kitchen_Excellent + Kitchen_Fair + Kitchen_Good +  Kitchen_Poor + Kitchen_VeryGood + Kitchen_VeryPoor + KITCHENS + FullBath_Excellent + FullBath_Fair + FullBath_Good + FullBath_Poor + FullBath_VeryGood + FULLBATHS + Cond_VeryPoor + Cond_Excellent + Cond_Fair + Cond_Good + Cond_Poor + Cond_VeryGood + Qual_A + Qual_B + Qual_D + Qual_E +  BEDROOMS + Cape_Cod + Milwaukee_Bungalow + Res_OS_A + Colonial + Duplex + Res_OS_2sty + Other, data = fitdata)

summary(mod)
anova(mod)

ICC = (0.1215)/(0.6306 +0.1215)
ICC

r.squaredGLMM(mod)

# Of the variance of an observation, 16.15% of this variation is the result of differences 
# between Census Tracts. 

# 83.85 % of this variation is the result of differences within Census Tracts


```


Visuals
```{r}
p1 <- ggplot(resdata, aes(x=MEDIAN.INCOME)) + 
  geom_density()

p1 +geom_vline(aes(xintercept=mean(MEDIAN.INCOME)),
            color="blue", linetype="dashed", size=1)


# Fat Tails
p2 <- ggplot(resdata, aes(x=atsratio)) + 
  geom_density()

p2 +geom_vline(aes(xintercept=mean(atsratio)),
            color="blue", linetype="dashed", size=1)


# Right Tail Distribution 
#temp <- resdata %>% filter(SALEPRICE < 1000000) still right tailed even if you get rid of 14 mil observation
p3 <- ggplot(resdata, aes(x=SALEPRICE)) + 
  geom_density()

p3 +geom_vline(aes(xintercept=mean(SALEPRICE)),
            color="blue", linetype="dashed", size=1)



p4 <- ggplot(resdata, aes(x=Percent_Renter)) + 
  geom_density()

p4 +geom_vline(aes(xintercept=mean(Percent_Renter)),
            color="blue", linetype="dashed", size=1)



p5 <- ggplot(resdata, aes(x=Percent_Black)) + 
  geom_density()

p5 +geom_vline(aes(xintercept=mean(Percent_Black)),
            color="blue", linetype="dashed", size=1)



p6 <- ggplot(resdata, aes(x=Percent_White)) + 
  geom_density()

p6 +geom_vline(aes(xintercept=mean(Percent_White)),
            color="blue", linetype="dashed", size=1)

```



Shapefile
```{r}
Mil_County<-st_read("C:/Users/Vinnie/Desktop/GitHub/Milwaukee-Property-Assessment/Shapefiles/Census_Tracts.shp")
#Makeup
st_geometry_type(Mil_County)
#Coordinate Reference System
st_crs(Mil_County)
#World Geodetic System 1984


Mil_County2 <- Mil_County %>%
  filter(OBJECTID != 263) %>%
  rename(GEO_TRACT = Tract_ID_I)

ggplot() + 
  geom_sf(data = Mil_County2, color = "black", fill = "pink") + 
  ggtitle("Milwaukee!") + 
  coord_sf()


```



```{r}

Remove <- setdiff(Mil_County2$GEO_TRACT,resdata$GEO_TRACT)

temp <- Mil_County2 %>% 
  left_join(resdata, by = "GEO_TRACT") %>%
  mutate(lighter = ifelse(GEO_TRACT %in% Remove, 1,0))

temp2 <- temp %>% filter(lighter==1)
#%>%
  #filter(!GEO_TRACT %in% Remove)


```



```{r}
ggplot() + 
  geom_sf(aes(fill=salesdecile), color='transparent', data = temp) +
  geom_sf(fill = 'transparent', color='white', data = temp) + 
  geom_sf(fill='grey90', color = 'white',data = temp2)+
  scale_fill_viridis_c(name ='Sale Decile')+
  ggtitle("Milwaukee Sale Price Deciles") + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank())+
  coord_sf()

#ggsave("Sales Decile.png", width = 5.5, height = 7)

```


```{r}
#resdata <- resdata %>% left_join(Mil_County2, by = "GEO_TRACT")

ggplot() + 
  geom_sf(aes(fill=Percent_Black), color='transparent', data = temp) +
  geom_sf(fill = 'transparent', color='white', data = temp) + 
  geom_sf(fill='grey90', color = 'white',data = temp2)+
  scale_fill_viridis_c(name ='Percent Black')+
  ggtitle("Milwaukee Census Tracts by Percent Black Population") + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank())+
  coord_sf()

#ggsave("Percent Black Population.png", width = 5.5, height = 7)
```

```{r}
ggplot() + 
  geom_sf(aes(fill=Percent_White), color='transparent', data = temp) +
  geom_sf(fill = 'transparent', color='white', data = temp) + 
  geom_sf(fill='grey90', color = 'white',data = temp2)+
  scale_fill_viridis_c(name ='Percent White')+
  ggtitle("Milwaukee Census Tracts by Percent White Population") + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank())+
  coord_sf()

#ggsave("Percent White Population.png", width = 5.5, height = 7)
```




```{r}

ggplot() + 
  geom_sf(aes(fill=IncomeDecile), color='transparent', data = temp) +
  geom_sf(fill = 'transparent', color='white', data = temp) + 
  geom_sf(fill='grey90', color = 'white',data = temp2)+
  scale_fill_viridis_c(name ='Income Decile')+
  ggtitle("Milwaukee Census Tracts by Income Deciles") + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank())+
  coord_sf()

#ggsave("Income Deciles.png", width = 5.5, height = 7)

```



```{r}
ggplot() + 
  geom_sf(aes(fill=MedianATSRatio), color='transparent', data = temp) +
  geom_sf(fill = 'transparent', color='white', data = temp) + 
  geom_sf(fill='grey90', color = 'white',data = temp2)+
  scale_fill_viridis_c(name ='Sale Decile')+
  ggtitle("Milwaukee Sale Price Deciles") + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank())+
  coord_sf()

#ggsave("Sales Decile.png", width = 5.5, height = 7)

```


###





###




###




# Another Method of Grabbing Maps

```{r}
library(tidyverse)
library(tidycensus)
library(sf)
library(tigris)
#you need to let R know to bring in the spatial data as sf objects
options(tigris_class = "sf")
#library(tmap)
```



```{r}
#census_api_key("d4223dab8dbc2a3dd81afcedb9f3d52c8ad2d47d")

wi.tracts <- get_acs(geography = "tract", 
              year = 2018,
              variables = c(medincome = "B19013_001", 
                            fb = "B05012_003", totp = "B05012_001"), 
              state = "WI",
              survey = "acs5",
              geometry = TRUE)
```


```{r}
wi.tracts <- wi.tracts %>%
              select(-(moe)) %>%
            spread(key = variable, value = estimate) %>%
            mutate(pfb = fb/totp) %>%
  filter(grepl("Milwaukee County",NAME))
  

ggplot(wi.tracts) + geom_sf()
```

We were curious to see if the LASSO procedure would shrink any coefficients to zero

Black Population
```{r}

fitdata <- resdata %>% 
  select(atsratio,
         Percent_Black,
         PctSalePriceDiff_Below,PctSalePriceDiff_Above,PctSalePriceDiff_Below,
         LogMedianIncome,LogMedianTractSalesPrice,GEO_TRACT)
 
scaled.dat <- fitdata %>% 
  select(-c("GEO_TRACT")) %>% scale(center = T,scale=T)

fitdata <- as.data.frame(scaled.dat) %>% 
  mutate(GEO_TRACT = fitdata$GEO_TRACT)

covariates <- resdata %>% select(Kitchen_Excellent, Kitchen_Fair, Kitchen_Good, Kitchen_Poor, Kitchen_VeryGood, Kitchen_VeryPoor, KITCHENS,FullBath_Excellent,FullBath_Fair,FullBath_Good,FullBath_Poor,FullBath_VeryGood,FULLBATHS, Cond_VeryPoor,Cond_Excellent,Cond_Fair,Cond_Good,Cond_Poor,Cond_VeryGood, Qual_A,Qual_B,Qual_D,Qual_E, BEDROOMS,Cape_Cod,Milwaukee_Bungalow,Res_OS_A,Colonial,Duplex,Res_OS_2sty,Other)


fitdata <- cbind(fitdata,covariates)

lasso_data <- fitdata %>% select(-c("GEO_TRACT"))

x_vars <- model.matrix(atsratio ~.,lasso_data)[,-1]
y_var <- lasso_data$atsratio
grid = 10^seq(10, -2, length = 100)

lasso <- glmnet(x_vars, y_var, alpha = 1, lambda = grid)
plot(lasso)

cv.out = cv.glmnet(x_vars,y_var, alpha = 1)
plot(cv.out)

bestlam <- cv.out$lambda.min
out <- glmnet(x_vars,y_var, alpha = 1, lambda=grid)
lasso_coef = predict(out,type='coefficients',s=bestlam)
lasso_coef

```


```{r}
fitdata <- resdata %>% 
  select(atsratio,
         Percent_NotHispanic_White,
         PctSalePriceDiff_Below,PctSalePriceDiff_Above,PctSalePriceDiff_Below,
         LogMedianIncome,LogMedianTractSalesPrice,GEO_TRACT)
 
scaled.dat <- fitdata %>% 
  select(-c("GEO_TRACT")) %>% scale(center = T,scale=T)

fitdata <- as.data.frame(scaled.dat) %>% 
  mutate(GEO_TRACT = fitdata$GEO_TRACT)

covariates <- resdata %>% select(Kitchen_Excellent, Kitchen_Fair, Kitchen_Good, Kitchen_Poor, Kitchen_VeryGood, Kitchen_VeryPoor, KITCHENS,FullBath_Excellent,FullBath_Fair,FullBath_Good,FullBath_Poor,FullBath_VeryGood,FULLBATHS, Cond_VeryPoor,Cond_Excellent,Cond_Fair,Cond_Good,Cond_Poor,Cond_VeryGood, Qual_A,Qual_B,Qual_D,Qual_E, BEDROOMS,Cape_Cod,Milwaukee_Bungalow,Res_OS_A,Colonial,Duplex,Res_OS_2sty,Other)


fitdata <- cbind(fitdata,covariates)

lasso_data <- fitdata %>% select(-c("GEO_TRACT"))

x_vars <- model.matrix(atsratio ~.,lasso_data)[,-1]
y_var <- lasso_data$atsratio
grid = 10^seq(10, -2, length = 100)

lasso <- glmnet(x_vars, y_var, alpha = 1, lambda = grid)
plot(lasso)

cv.out = cv.glmnet(x_vars,y_var, alpha = 1)
plot(cv.out)

bestlam <- cv.out$lambda.min
out <- glmnet(x_vars,y_var, alpha = 1, lambda=grid)
lasso_coef = predict(out,type='coefficients',s=bestlam)
lasso_coef
```


```{r}
fitdata <- resdata %>% 
  select(atsratio,
         Percent_Hispanic,
         PctSalePriceDiff_Below,PctSalePriceDiff_Above,PctSalePriceDiff_Below,
         LogMedianIncome,LogMedianTractSalesPrice,GEO_TRACT)
 
scaled.dat <- fitdata %>% 
  select(-c("GEO_TRACT")) %>% scale(center = T,scale=T)

fitdata <- as.data.frame(scaled.dat) %>% 
  mutate(GEO_TRACT = fitdata$GEO_TRACT)

covariates <- resdata %>% select(Kitchen_Excellent, Kitchen_Fair, Kitchen_Good, Kitchen_Poor, Kitchen_VeryGood, Kitchen_VeryPoor, KITCHENS,FullBath_Excellent,FullBath_Fair,FullBath_Good,FullBath_Poor,FullBath_VeryGood,FULLBATHS, Cond_VeryPoor,Cond_Excellent,Cond_Fair,Cond_Good,Cond_Poor,Cond_VeryGood, Qual_A,Qual_B,Qual_D,Qual_E, BEDROOMS,Cape_Cod,Milwaukee_Bungalow,Res_OS_A,Colonial,Duplex,Res_OS_2sty,Other)


fitdata <- cbind(fitdata,covariates)

lasso_data <- fitdata %>% select(-c("GEO_TRACT"))

x_vars <- model.matrix(atsratio ~.,lasso_data)[,-1]
y_var <- lasso_data$atsratio
grid = 10^seq(10, -2, length = 100)

lasso <- glmnet(x_vars, y_var, alpha = 1, lambda = grid)
plot(lasso)

cv.out = cv.glmnet(x_vars,y_var, alpha = 1)
plot(cv.out)

bestlam <- cv.out$lambda.min
out <- glmnet(x_vars,y_var, alpha = 1, lambda=grid)
lasso_coef = predict(out,type='coefficients',s=bestlam)
lasso_coef

```

```{r}
fitdata <- resdata %>% 
  select(atsratio,
         PctSalePriceDiff_Below,PctSalePriceDiff_Above,PctSalePriceDiff_Below,
         LogMedianIncome,LogMedianTractSalesPrice,GEO_TRACT)
 
scaled.dat <- fitdata %>% 
  select(-c("GEO_TRACT")) %>% scale(center = T,scale=T)

fitdata <- as.data.frame(scaled.dat) %>% 
  mutate(GEO_TRACT = fitdata$GEO_TRACT)

covariates <- resdata %>% select(Kitchen_Excellent, Kitchen_Fair, Kitchen_Good, Kitchen_Poor, Kitchen_VeryGood, Kitchen_VeryPoor, KITCHENS,FullBath_Excellent,FullBath_Fair,FullBath_Good,FullBath_Poor,FullBath_VeryGood,FULLBATHS, Cond_VeryPoor,Cond_Excellent,Cond_Fair,Cond_Good,Cond_Poor,Cond_VeryGood, Qual_A,Qual_B,Qual_D,Qual_E, BEDROOMS,Cape_Cod,Milwaukee_Bungalow,Res_OS_A,Colonial,Duplex,Res_OS_2sty,Other)


fitdata <- cbind(fitdata,covariates)

lasso_data <- fitdata %>% select(-c("GEO_TRACT"))

x_vars <- model.matrix(atsratio ~.,lasso_data)[,-1]
y_var <- lasso_data$atsratio
grid = 10^seq(10, -2, length = 100)

lasso <- glmnet(x_vars, y_var, alpha = 1, lambda = grid)
plot(lasso)

cv.out = cv.glmnet(x_vars,y_var, alpha = 1)
plot(cv.out)

bestlam <- cv.out$lambda.min
out <- glmnet(x_vars,y_var, alpha = 1, lambda=grid)
lasso_coef = predict(out,type='coefficients',s=bestlam)
lasso_coef

```









GOODNESS OF FIT

We want to test the distribution of our Dependent variable 

##### NEED HELP #####

```{r}
set.seed(10)
hist(resdata$atsratio)
samp <- sample(resdata$atsratio, size = 4000, replace = F)
hist(samp)

# Normal Distribution

gof.norm <- gofTest(samp, distribution = "norm")
gof.norm$p.value

plot(gof.norm)

# Log Transformed

gof.lognorm <- gofTest(log(samp), distribution = "norm")
gof.lognorm$p.value

plot(gof.lognorm)


# Gamma Distribution


gof.gamma <- gofTest(samp, distribution = "gamma")
gof.gamma$p.value

plot(gof.gamma)

# Gamma with Corrected MLE

gof.gammacorrectedmle <- gofTest(samp,distribution = "gamma",
                                 est.arg.list = list(method="bcmle"))
gof.gammacorrectedmle$p.value

plot(gof.gammacorrectedmle)


# KS Test Gamma

gof.gammaks <- gofTest(samp, test = 'ks',distribution = "gamma")
gof.gammaks$p.value

plot(gof.gammaks)

# Lnorm Test

gof.lnorm <- gofTest(samp, distribution = "lnorm")
gof.lnorm$p.value

plot(gof.lnorm)

# Shapiro Wilk Test

shapiro.test(samp)

# KS Test

ks.test(samp,'pnorm',m=0.89,sd=0.13)

ks.test(samp,'pnorm',m=0,sd=1)

# Box Cox

boxcox.list <- boxcox(samp)

plot(boxcox.list)

plot(boxcox.list, plot.type = "Q-Q Plots") 

```
